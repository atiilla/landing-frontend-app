---
title: "Deep Learning and Feature Extraction"
subtitle: "Makine Öğrenmesinden Derin Öğrenmeye Geçiş: Otomatik Özellik Çıkarma Avantajları ve Etkisi"
summary: "Derin öğrenmede otomatik özellik çıkarma yaklaşımı, temel ilkeleri ve avantajlarıyla ele alınmıştır. Yapay zekâ, makine öğrenmesi ve derin öğrenme arasındaki ilişkiler açıklanmış, ardından yapay sinir ağlarının yapısı ve işlevleri incelenmiştir. Derin öğrenmede kullanılan sinir ağı mimarilerinin, geleneksel makine öğrenmesindeki manuel özellik çıkarımına kıyasla nasıl daha otomatik ve etkili çalıştığı vurgulanmıştır. Otomatik özellik çıkarımının, görüntü, metin ve zaman serisi gibi karmaşık veri türlerindeki üstün performansı üzerinde durulmuştur. Son olarak, derin öğrenme modellerinin esnekliği ve özelleştirilebilir mimarilerinin karmaşık problemlerin çözümüne sunduğu katkılar değerlendirilmiştir. Metin, derin öğrenmenin modern yapay zekâ uygulamalarındaki önemini ve özellik çıkarımındaki dönüştürücü etkisini ortaya koymayı hedeflemektedir."
publishedAt: "2025-02-13"
author: "Muhammed ŞEN"
tags: ["machinelearning","deeplearning"]
---
# Makine Öğrenmesinden Derin Öğrenmeye Geçiş: Otomatik Özellik Çıkarma Avantajları ve Etkisi

**Muhammed Sen**  
Firat University Computer Engineering  
muhammedsnfu@gmail.com

## Özet

Derin öğrenmede otomatik özellik çıkarma yaklaşımı, temel ilkeleri ve avantajlarıyla ele alınmıştır. Yapay zekâ, makine öğrenmesi ve derin öğrenme arasındaki ilişkiler açıklanmış, ardından yapay sinir ağlarının yapısı ve işlevleri incelenmiştir. Derin öğrenmede kullanılan sinir ağı mimarilerinin, geleneksel makine öğrenmesindeki manuel özellik çıkarımına kıyasla nasıl daha otomatik ve etkili çalıştığı vurgulanmıştır. Otomatik özellik çıkarımının, görüntü, metin ve zaman serisi gibi karmaşık veri türlerindeki üstün performansı üzerinde durulmuştur. Son olarak, derin öğrenme modellerinin esnekliği ve özelleştirilebilir mimarilerinin karmaşık problemlerin çözümüne sunduğu katkılar değerlendirilmiştir. Metin, derin öğrenmenin modern yapay zekâ uygulamalarındaki önemini ve özellik çıkarımındaki dönüştürücü etkisini ortaya koymayı hedeflemektedir.

## Anahtar Kelimeler

- Derin Öğrenme
- Otomatik Özellik Çıkarma 
- Yapay Sinir Ağları
- Makine Öğrenmesi
# 1. Giriş

Derin öğrenmede otomatik özellik öğrenme yaklaşımını tam anlamak için öncelikle Derin öğrenmenin ne olduğunu bilmemiz gerekir hatta daha geniş düşünürsek Yapay Zekâ ve Makina öğrenmesinin ne olduğuna Derin öğrenmenin ne zaman ve neden çıktığına bakmamız gerekebilir ancak bu kavramları tam olarak anlayabilirsek Derin öğrenmede otomatik özellik öğrenme yaklaşımının ne olduğunu nasıl geliştiğini modellerimizi oluştururken sağladığı faydaları görebiliriz.

## 1.1. Yapay Zekâ Nedir?

1990 yılında yayımlanan bir kitapta, yapay zekâ (YZ) şöyle tanımlanmıştır: Yapay Zekâ, insan zekâsını taklit etmeye çalışan ve insan yapımı makineler aracılığıyla çeşitli görevleri yerine getiren bir teknolojidir. Ancak, YZ'nin ne olduğunu tam olarak anlayabilmek için "zekâ" kavramını doğru bir şekilde tanımlamak gerekir. Zekâ, deneyimlerden öğrenme, sorunları çözme ve yeni durumlara hızlıca uyum sağlama gibi yetenekleri kapsar.
YZ'nin "yapay" olmasının anlamı, onun doğal evrimsel süreçlerle ya da biyolojik etkilerle değil, insanlar tarafından tasarlanarak yaratılmasıdır. Yani, yapay zekâ, doğada bulunan zekâya benzer yetenekleri taklit etse de biyolojik bir temele dayanmaz [1]. Bu tanımdan yola çıkarak, yapay zekânın amacı, deneyimlerden elde edilen bilgileri analiz ederek doğru sonuca ulaşmaktır.
Bunu daha iyi anlayabilmek için, bir bebeğin öğrenme sürecini ele alabiliriz. Bebekler doğduklarında konuşma yeteneğine sahip değildir. Zamanla çevrelerinden aldığı bilgileri deneyimleyerek ve tekrarlar yaparak dil becerilerini geliştirirler. Bu süreç, öğrenme ve yorumlama yoluyla gerçekleşir. Yapay zekâ da benzer şekilde, daha önceki deneyimlerden öğrenerek ve analiz yaparak "zekâ" sergileyebilir.


## 1.2.	Makine Öğrenmesi Nedir?

Makine öğrenmesi 2015 yılında yayımlanan bir kitapta şöyle bir tanımlamayla açıklanmaya çalışılmıştır kısaca açıklamak gerekirse: Makine öğrenmesi, algoritmaların giriş verileriyle eğitim alarak belirli görevleri daha iyi yapmalarını sağlayan bir süreçtir. Algoritmalar, sabit kodlama yerine verilerle deneyim kazandıkça kendilerini optimize eder ve yeni verilerle doğru sonuçlar üretir [2]. Yani Yapay zekayla bağlantısını tam olarak açıklamak gerekirse: Makine öğrenmesi, yapay zekânın (YZ) bir alt alanıdır ve yapay zekânın amacına hizmet eden önemli bir tekniktir. Yapay zekâ, insan benzeri zekâ ve öğrenme süreçlerini taklit etmeyi amaçlayan bir alandır. Makine öğrenmesi ise, bu hedefe ulaşmak için kullanılan bir yöntemdir.
Makine öğrenmesinde, algoritmalar, insan benzeri öğrenme süreçlerine benzer şekilde, verilerden öğrenerek performanslarını geliştirirler. İnsanlar gibi, makine öğrenmesi algoritmaları da zamanla yeni verilerle "deneyim" kazanır ve buna göre kendilerini optimize ederler. Bu, yapay zekânın "öğrenme" yeteneğiyle ilgilidir. YZ, verilen verilerle zamanla daha doğru tahminler yapabilen, daha akıllı hale gelen sistemler yaratmayı hedefler.
Sonuç olarak, makine öğrenmesi, yapay zekânın gerçek zekâ ve öğrenme kabiliyetini taklit etmesinin temel yoludur. Bu, tıpkı insanların öğrenme biçimine benzer şekilde, algoritmaların verilerle "öğrenmesi" ve yeni durumlara uyum sağlaması anlamına gelir.

## 1.3. Derin Öğrenme Nedir?

Derin öğrenmeyi açıklayan bir makalede şöyle bir tanım vardır: Derin öğrenme, verilerin yüksek düzeyde soyutlamalarını modellemeye çalışan bir makine öğrenmesi dalıdır ve bu, karmaşık yapılar veya doğrusal olmayan dönüşümlerden oluşan çoklu sinir katmanları kullanarak yapılır [3]. Tanım biraz karmaşık gelmiş olabilir fakat daha açıklayıcı olmak gerekirsek Derin öğrenme, bilgisayarların insan gibi düşünmesini sağlamaya çalışan bir yapıdır. Bu yapı, bilgisayarların çok büyük veri yığınlarından, kendi başlarına öğrenmelerini ve çeşitli görevleri yerine getirebilmelerini sağlar.

<img
  src="/blog/022025/image1.jpg" 
  alt="Derin öğrenmenin verileri birden fazla katman aracılığıyla nasıl işlediğine dair bir örnek" 
  style={{ width: "50%" }}
/>


Bir örnekle açıklayalım: Farz edelim ki bilgisayara çok sayıda fotoğraf gösteriyorsunuz. Bu fotoğrafların bazıları Kadın, bazıları ise Erkek. Başlangıçta bilgisayar hiçbir şey anlamaz, ama zamanla kadınlar ve erkekleri ayırt etmeyi öğrenir. Derin öğrenme sayesinde, bilgisayar, fotoğrafları tek tek inceleyerek, "bu bir kadın, bu bir erkek" gibi etiketler koymayı öğrenir. Her seferinde daha fazla veri gösterdikçe, bilgisayar daha doğru tahminler yapmaya başlar. Yani bu örnekten da anlaşıldığı üzere bilgisayara sunulan fotoğraflar bilgisayarın deneyim kazanmasına ve aslında spesifik ve onun hiç bilmediği bir durumu öğrenerek yorumlamasına zemin hazırlamış oluyor. Tabi bu durum verdiğim örnekteki kadar kolay bir şekilde gerçekleşmiyor.
Derin öğrenme, bilgisayarların önce basit özellikleri, sonra karmaşık nesneleri öğrenmesini sağlar. İlk aşamada kenar ve renk gibi temel öğeler öğrenilir. İleri aşamalarda ise daha karmaşık yapılar, örneğin nesneler veya kavramlar, tanınır. 


# 2. Derin Öğrenmede Sinir Ağları ve Özellik Öğrenme

Bu bölümde, derin öğrenme yöntemlerinde yapay sinir ağlarının neden ortaya çıktığını ve özellik çıkarımının neden önemli olduğunu inceleyeceğiz. Yazının önceki kısımlarında temel bilgileri ele aldığımızı düşünerek, burada konuyu daha derinlemesine ve kapsamlı bir şekilde ele alacağız. Amacımız, konuyu daha anlaşılır kılarken aynı zamanda karmaşık noktaları da açıklığa kavuşturmak.
## 2.1. Derin Öğrenme Yöntemlerinde Yapay Sinir Ağı ve Özellik Çıkarımının Önemi

To fully comprehend deep learning methods, it is essential to investigate the following key concepts:

- **Yapay Sinir Ağlarının (YSA) Temelleri**  
- **Derin Öğrenme Mimarileri**  
- **Aktivasyon Fonksiyonları**  
- **Optimizasyon Algoritmaları**  
- **Veri İşleme**

Derin öğrenme, önceden ele alınan kavramlardan çok daha karmaşık bir yapıya sahiptir. Bu temel kavramları anladığımızda, özellik çıkarımının neden yapıldığını ve derin öğrenmedeki otomatik özellik çıkarımı ile manuel özellik çıkarımı arasındaki farkları daha net bir şekilde görebiliriz. Otomatik özellik çıkarımı, modelin verileri analiz ederek kendisinin öğrenmesini sağlar, bu da manuel özellik çıkarımına göre daha hızlı ve doğru sonuçlar elde edilmesini sağlar. Bir örnek üzerinden bunu daha somutlaştırabiliriz: Bir görüntüde kedileri tanımak istediğimizi varsayalım. Manuel özellik çıkarımında, kedinin kulaklarının şekli, göz yapısı veya kuyruk uzunluğu gibi özellikleri biz belirleriz. Ancak derin öğrenme modeli, bu özellikleri görüntülerdeki verileri analiz ederek otomatik olarak öğrenir. İlk katmanlar basit kenar ve köşe gibi yapıların farkına varırken, daha derin katmanlar kedinin genel şekil ve yapısını tanır. Bu sayede model, kediyi daha yüksek doğrulukla tanıyabilir.

## 2.1.1. Yapay Sinir Ağı Temelleri

Yapılan bir çalışmada yapay sinir ağları şöyle tanımlanmıştır. Yapay sinir ağları (Artificial Neural Networks-ANN), insan beyninin karmaşık, doğrusal olmayan ve paralel bilgi işleme yeteneklerinden ilham alarak geliştirilmiştir. Bu ağlar, biyolojik sinir hücrelerinin (nöronların) yapı ve işleyişini taklit ederek, beynin örüntü tanıma, karar alma gibi görevleri nasıl yerine getirdiğini simüle etmeye çalışır. ANN'ler, sinaptik bağlantılar, aksonlar ve dendritler gibi temel biyolojik öğelerden esinlenerek, elektrik sinyallerini işleyen ve uyaranlara yanıt üreten yapay nöronlar oluşturur [4].
Yine farklı bir çalışmada da şöyle bir açıklamaya yer verilmiştir: Yapay sinir ağları (YSA), insan beyninin karmaşık, doğrusal olmayan ve paralel bilgi işleme yeteneklerinden ilham alarak geliştirilmiştir. Bu durum biyolojik sinir hücrelerinin (nöronların) yapı ve işleyişini taklit ederek, beynin örüntü tanıma, karar alma gibi görevleri nasıl yerine getirdiğini simüle etmeye çalışır [5]. Yapay sinir ağları, biyolojik sinir hücrelerindeki sinaptik bağlantılar, aksonlar ve dendritlerden esinlenerek elektrik sinyallerini işleyen ve uyaranlara yanıt üreten yapay nöronlar oluşturur. Basit bir yapay sinir ağı, temelde üç ana katmandan oluşur:

- **Girdi Katmanı (Input Layer)**:  
  Bu katman ham veriyi alır ve herhangi bir hesaplama yapmadan doğrudan sonraki katmana iletir.

- **Gizli Katman (Hidden Layer)**:  
  Modelin öğrenme ve girdi verilerinden temel özellikleri çıkardığı katmandır. Bu katman, verilerdeki desenleri ve ilişkileri ortaya çıkarmak için karmaşık dönüşümler gerçekleştirir.

- **Çıktı Katmanı (Output Layer)**:  
  Modelin sınıflandırmalar, tahminler veya ilgili göreve dayalı diğer sonuçları ürettiği katmandır.


<img
  src="/blog/022025/image2.jpg" 
  alt="Basit bir yapay sinir ağının çizimi" 
  style={{ width: "50%" }}
/>


Yukarıda gördüğümüz görsel, basit bir yapay sinir ağını göstermektedir. Görselde giriş katmanı, gizli katman ve çıkış katmanı sırasıyla yer almaktadır. Bu yapıyı daha anlaşılır hale getirmek için bir örnek üzerinden inceleyebiliriz. Örneğimiz, derin öğrenmeye yeni başlayanların bilebileceği bir duruma dayanıyor: Kiralık bir ev arayan bir aileyi düşünelim. Bu ailenin evde aradığı bazı özellikler var; bunlar evin büyüklüğü, oda sayısı, evin yaşı ve konumu gibi kriterler olabilir. Bu özellikleri yapay sinir ağına giriş (girdi) olarak veriyoruz.
İlk olarak, bu özellikler giriş katmanında alınır ve bir sonraki katman olan gizli katmana iletilir. Giriş katmanı, verilerin sinir ağına giriş yaptığı yerdir. Gizli katman ise, bu özellikler arasındaki ilişkileri öğrenmeye başladığımız bölümdür. Gizli katmanda, her bir özellik diğer özelliklerle etkileşime girerek, evin fiyatını etkileyen ilişkileri öğrenir. Bu sayede, yeni özellikler ya da çıkarımlar elde edilebilir. Örneğin, x1 evin büyüklüğünü, x2 oda sayısını, x3 evin yaşını ve x4 evin konumunu temsil etsin. Gizli katmanda bu özellikler arasındaki ilişkiler analiz edilerek, örneğin evin sağlamlık durumu veya okul kalitesi gibi yeni bilgiler çıkarılabilir.
Bu durumda, evin büyüklüğü, oda sayısı, evin yaşı ve konumu gibi temel kriterlere göre bazı çıkarımlar yapabiliriz. Çocukları olan bir ailenin geniş bir eve ihtiyaç duyacağını, oda sayısının fazla olması gerektiğini düşünebiliriz. Eğer aile, yeni ve güvenilir bir ev arıyorsa, evin yaşının küçük olması gerektiği gibi bir sonuç çıkarabiliriz. Ayrıca, aile nezih bir bölgede yaşamak istiyorsa, çocuklarının kaliteli okullara erişebileceği bir konumda ev aramak isteyebilir.
Son olarak, bu verilerin tümü işlenerek çıkış katmanında bir fiyat tahmini yapılır. Fiyat tahmininin yapıldığı bu son nokta, bizim çıkış katmanımızdır. Tüm bu aşamalar sonucunda, yapay sinir ağı bize aranan özelliklere uygun bir evin tahmini fiyatını verebilir.

### 2.1.2.	Derin Öğrenme Mimarileri
Deep learning distinguishes itself from classical artificial neural networks by employing models with significantly more hidden layers. These deeper structures enhance the network's complexity, resulting in improved accuracy. Common deep learning architectures include Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformers. Each architecture excels at processing specific types of data. For instance, CNNs are particularly effective for image data, while RNNs are often used for time-series data and natural language processing tasks [6].

### 2.1.3.	Aktivasyon Fonksiyonları
In artificial neural networks, the output of each neuron is shaped by an activation function. Activation functions enable the network to exhibit non-linear behavior, thereby allowing the model to learn more complex relationships within the data. One widely used activation function is the Rectified Linear Unit (ReLU). ReLU eliminates negative values while retaining positive values, thereby directing the model’s focus toward meaningful features. This process not only speeds up learning but also filters out irrelevant information. ReLU is favored in deep learning due to its computational efficiency, which accelerates the training process [7].

### 2.1.4.	Optimizasyon Algoritmaları
Yapay sinir ağlarının eğitilmesinde, öğrenme sürecini en hızlı ve etkili şekilde yönlendiren algoritmalar kullanılır. Optimizasyon algoritmaları, modelin ağırlıklarını güncelleyerek hata fonksiyonunu minimize etmeyi hedefler. En yaygın optimizasyon algoritmalarından biri Stokastik Gradyan İnişi (SGD)'dir, ancak daha gelişmiş yöntemler arasında Adam, Adagrad ve RMSProp gibi algoritmalar da bulunur. Bu algoritmalar, daha hızlı ve daha stabil öğrenme süreçleri sağlar. Adam algoritması, öğrenme oranlarını dinamik olarak ayarlayarak modelin daha verimli öğrenmesini sağlar [8].


### 2.1.5. Veri İşleme

Derin öğrenme modellerinin başarısı, büyük miktarda etiketlenmiş verilere dayanır. Bu verilerin doğru şekilde işlenmesi ve modellenmesi, yüksek doğruluklu sonuçlar elde etmede kritik rol oynar. Veri ön işleme adımları, verilerin normalize edilmesi, eksik verilerin tamamlanması ve verilerin uygun şekilde etiketlenmesi gibi işlemleri içerir. Ayrıca, veri artırma teknikleri de modelin genelleme yeteneğini artırmak için sıklıkla kullanılır. Veri artırma, özellikle görüntü işleme alanında, modelin daha fazla çeşitlilikte veri görmesini sağlayarak overfitting (aşırı uyum) riskini azaltır.

Farklı bir örnek daha vererek anlattıklarımızın daha doğru bir şekilde anlaşılmasını sağlayabiliriz örneğimiz bir görsel olsun mesela: Elinizde 64x64 boyutlarında bir araba görseli olduğunu varsayalım. Bu görselde her bir piksel, belirli bir renk veya yoğunluk değeri taşır. Bu pikselleri giriş katmanına ileteceğiz. Her piksel, yapay sinir ağına veriyi tanıtmak için bir nöron gibi işlev görür. Bu durumda, ağın giriş katmanında toplam 4,096 nöron (64 x 64 piksel) olacaktır. Şimdi, teorik kısmı örneğinizle birleştirerek nasıl işlediğini açıklayalım.

<img
  src="/blog/022025/image3.jpg" 
  alt="Motosiklet örneği" 
  style={{ width: "50%" }}
/>


<img
  src="/blog/022025/image4.jpg" 
  alt="Araba örneği" 
  style={{ width: "50%" }}
/>


- **Giriş Katmanı**  
  Giriş katmanı, ham verilerin (piksel değerlerinin) doğrudan sinir ağına aktarıldığı ilk katmandır. Her piksel bir nöron gibi işlev görür. Bu katman, herhangi bir işlem yapmaz; sadece verileri bir sonraki katmana iletir. Bu noktada, her piksel model tarafından henüz "önemli" veya "önemsiz" olarak değerlendirilmez. Hepsi başlangıçta eşit derecede önemli kabul edilir.  
  Veri işleme süreci burada devreye girer: Görsel veriler genellikle normalize edilerek (örneğin, 0 ile 1 arasında bir ölçek kullanılarak) giriş katmanına iletilir. Normalizasyon, modelin daha hızlı ve kararlı bir şekilde öğrenmesini sağlar.

- **Gizli Katman**  
  Gizli katman, modelin asıl öğrenme ve özellik çıkarma işlemlerini gerçekleştirdiği katmandır. Görseldeki her piksel arasındaki ilişkiler bu katmanda analiz edilir. İlk katmanlar piksellerin temel özelliklerini, örneğin kenarları, köşeleri veya dokuları öğrenirken, daha derin katmanlar daha soyut özellikleri öğrenmeye başlar.  
  Bu aşamada özellik çıkarımı gerçekleşir. Model, verileri analiz ederek nesneyi tanımaya yönelik daha karmaşık özellikler çıkarır. Örneğin, ilk katmanlar basit kenar ve renk değişimlerini algılarken, daha derin katmanlar nesnenin şekli ve yapısını tanımaya başlar.

- **Aktivasyon Fonksiyonu Kullanımı**  
  Gizli katmandaki her nöronun çıktısı genellikle bir aktivasyon fonksiyonundan geçer. Aktivasyon fonksiyonları, modelin doğrusal olmayan ilişkileri öğrenmesini sağlar. Örneğin, ReLU (Rectified Linear Unit) fonksiyonu, negatif değerleri sıfıra indirerek gereksiz ve anlamsız verilerin ağda ilerlemesini engeller.  
  Bu sayede model, yalnızca anlamlı ve pozitif özelliklere odaklanır, böylece öğrenme süreci hızlanır. Görsel verilerde bu işlem, örneğin kenarların veya belirli dokuların daha güçlü şekilde öğrenilmesini sağlar. Eğer bir pikselin değeri sıfır veya negatifse, bu değer sıfırlanır ve model sadece önemli bilgilere odaklanır.

- **Çıkış Katmanı**  
  Son olarak, çıkış katmanı devreye girer. Gizli katmanlardan elde edilen özellikler, çıkış katmanına iletilir. Bu katman, görseldeki özelliklere dayanarak nihai tahmini yapar. Örneğin, bir görselin bir araba olup olmadığını belirlemek için çıkış katmanındaki nöronlar, görselin öğrenilen özelliklerini (kenarlar, şekiller vb.) birleştirir ve bir sınıflandırma kararı verir. Bu örnekte model, "araba" veya "araba değil" gibi bir sınıf tahmini yapar.

Görselin her bir pikseli, giriş katmanında yer alan nöronlar tarafından doğrudan alınır ve gizli katmanlar tarafından işlenir. Gizli katmanlar, bu pikseller arasındaki ilişkileri analiz ederek görseldeki nesnenin temel özelliklerini öğrenir. Aktivasyon fonksiyonları, bu süreci doğrusal olmayan şekilde modüle eder. Son olarak, çıkış katmanında elde edilen özelliklere göre görselin bir araba olup olmadığı tahmin edilir.  
Bu süreç, derin öğrenme modellerindeki özellik çıkarımının ve otomatik öğrenmenin önemini net bir şekilde ortaya koyar. Model, görüntüdeki önemli özellikleri kendisi öğrenir ve bu sayede daha doğru ve hızlı sonuçlar elde edilir.



### 2.2. Makine Öğrenmesi ve Derin Öğrenmede Sinir Ağı Yapısı

- **Derin Öğrenmede Sinir Ağı Yapısı**
	Derin öğrenme, çok katmanlı yapılar kullanarak özellikleri otomatik olarak çıkarma yeteneğine sahiptir. Derin Sinir Ağları (Deep Neural Networks - DNN) olarak bilinen bu yapılar, birden fazla gizli katmana sahip olduklarından daha fazla veri işleyebilir ve daha karmaşık ilişkileri öğrenebilir. Bu gizli katmanlar sayesinde sinir ağı, verideki özellikleri hiyerarşik olarak, yani temel özelliklerden karmaşık özelliklere doğru çıkarır. Örneğin, bir görüntü işleme probleminde ilk katmanlar kenarları tanırken, sonraki katmanlar daha karmaşık şekilleri ve nesneleri tanıyabilir. Aşağıda temel bir derin sinir ağı yapısı görülmektedir.


<img
  src="/blog/022025/image5.jpg" 
  alt="Derin Sinir Ağının Katmanlı Yapısının Görselleştirilmesi" 
  style={{ width: "50%" }}
/>


-  **Makine Öğrenmesinde Sinir Ağı Yapısı**  
  Klasik makine öğrenmesinde genellikle Yapay Sinir Ağı (Artificial Neural Network - ANN) gibi daha basit yapılar kullanılır. Bu yapılar sınırlı sayıda gizli katmana sahip olup, veriy derinlemesine analiz edemez. Bu yüzden klasik makine öğrenmesi modellerinde özellik çıkarımının manuel olarak yapılması gerekir. Geliştiriciler, veriyi modelin daha iyi anlayabilmesi için özel özellikler çıkarmak zorundadır.  Örneğin, metin analizinde, kelime sıklığı, uzunluk, ya da belirli anahtar kelimeler gibi elle çıkarılmış özellikler modele verilir.

### 2.3. Özellik Çıkarımında: Makine Öğrenmesi ve Derin Öğrenmenin Farkı

#### • Makine Öğrenmesinde Elle Özellik Çıkarımı:
Klasik makine öğrenmesinde özellik çıkarımı süreci, geliştiricinin veriden anlamlı ve etkili özellikleri elle çıkarmasını gerektirir. Bu, modelin başarısı için kritik bir aşamadır. Örneğin, bir kredi skoru tahmini yaparken, geliştirici kişinin gelir düzeyi, kredi geçmişi ve meslek durumu gibi özellikleri belirleyerek modelin daha iyi tahmin yapabilmesini sağlar.

#### • Derin Öğrenmede Otomatik Özellik Çıkarımı:
Derin öğrenmede, sinir ağı özellikleri kendisi çıkarır. Sinir ağı, çok katmanlı yapısı sayesinde veriyi otomatik olarak analiz eder ve anlamlandırır. Özellikle görüntü, ses ve metin gibi ham verilerde, sinir ağı temel katmanlarda daha düşük seviyede özellikleri (örneğin, bir görüntüde kenarları veya renk dağılımını), daha üst katmanlarda ise daha karmaşık özellikleri (bir görüntüdeki nesneleri veya yüzleri) tanıyabilir. Bunu bir örnekle açıklarsak daha iyi anlaşılacaktır.

**Makine öğrenmesi yaklaşımında, görseldeki yüzlerin özelliklerini geliştiricinin elle çıkarması gerekir.** Model bu özellikleri öğrenir ve bu verilere dayanarak sınıflandırma yapar.

### Elle Tanımlanan Özellikler:
- **Yüz Hatlarının Şekli:** Kadın ve erkek yüzleri genel olarak belirgin farklılıklara sahiptir. Örneğin, erkeklerde çene hatları daha kare, kadınlarda ise daha yuvarlak olabilir.
- **Kaş Kalınlığı ve Şekli:** Erkek kaşları genelde daha kalın ve düz şekilli olabilirken, kadın kaşları daha kavisli olabilir.
- **Göz Mesafesi ve Göz Çevresi:** Gözler arasındaki mesafe veya göz çevresindeki belirgin özellikler cinsiyet ayrımında etkili olabilir.

**Model Eğitimi:** Bu özellikler bir makine öğrenmesi modeline verilir. Model, geliştiricinin sağladığı bu belirgin yüz özellikleri üzerinden sınıflandırma yapmayı öğrenir.  
Sonuç olarak model, geliştiricinin elle çıkardığı bu özellikler ile sınırlı olduğundan, farklı yüz tipleri veya bilinmeyen özellikler karşısında doğruluğu sınırlı olabilir.

Derin öğrenme modelinde ise yüz görselleri doğrudan sinir ağına verilir. Bu durumda, derin öğrenme modeli otomatik olarak yüzlerdeki belirgin özellikleri kendisi öğrenir.

- **Giriş Katmanı:** Yüz görseli piksel verileri olarak sinir ağına girer. Görüntüdeki her piksel, ağı bir katmandan diğerine geçerken özellikler çıkarmak için kullanılır.

- **Gizli Katmanlar ve Özellik Öğrenme:** Evrişimsel Sinir Ağları (CNN), çok katmanlı bir yapıda, yüz görsellerinin belirli özelliklerini çıkarır:  

- **İlk Katmanlar:** Temel özellikler, örneğin yüzün genel yapısı, gözler ve ağız gibi bölümler belirlenir.  

- **Orta Katmanlar:** Daha karmaşık yapılar, örneğin çene yapısı, burun şekli ve kaş kalınlığı gibi yüzün belirli ayrıntıları öğrenilir.  

- **Son Katmanlar:** Cinsiyet sınıflandırması için yüzün bütünsel özellikleri tanınır ve kadın veya erkek sınıfına ait olma ihtimalleri çıkarılır.  

- **Çıkış Katmanı:** Bu çıkarılan özellikler sonucu, model fotoğrafın kadın veya erkek olduğunu yüksek doğrulukla tahmin edebilir.

Derin öğrenme modelleri, özellik çıkarımını otomatik olarak gerçekleştirebilir; bu da elle özellik çıkarımı yapmaya gerek kalmadan, daha karmaşık yapıları tanımalarını sağlar. Bu sayede, sınıflandırma işlemleri daha doğru ve esnek hale gelir.  
**Özetle**, derin öğrenme, makine öğrenmesinin bir dalıdır ve daha kompleks yapıları öğrenip çözebilmesi için daha derin bir ağ yapısına sahiptir. Bu nedenle, daha karmaşık problemler üzerinde başarılı sonuçlar elde etmemize yardımcı olur. Örnek: Derin öğrenmede, sinir ağı mimarisi farklı konulara ve verilere göre özelleştirilebilir, bu da modelin özellik çıkarım şeklini değiştirebilir. Örneğin, **RNN (Tekrarlayan Sinir Ağı)**, özellikle sıralı ve zaman serisi verilerdeki ardışık bağımlılıkları yakalamak için kullanılır. Bu nedenle, **RNN’lerin** tasarımı ve çalışma prensibi, özellikle sıralı verilerdeki ilişkileri öğrenmeye yönelik olarak farklı bir özellik çıkarım yöntemine sahiptir.


### 3. Sonuç

Derin öğrenmede özellik çıkarımı, modellerin verideki özellikleri otomatik olarak öğrenebilmesi sayesinde manuel özellik çıkarımına gerek kalmadan gerçekleştirilir. Bu durum, derin öğrenmenin makine öğrenmesi yöntemlerine kıyasla daha esnek ve daha güçlü hale gelmesini sağlar. Manuel özellik çıkarımı yöntemleri, kullanıcıdan yoğun bilgi ve zaman gerektirirken, derin öğrenme mimarileri bu süreci çok daha otomatize bir hale getirmiştir. Özellikle, çok katmanlı sinir ağlarının (DNN) kullanımı, karmaşık yapıdaki veri türlerinin daha iyi analiz edilmesini ve öğrenilmesini sağlamıştır. Derin öğrenmenin bu otomatik özellik çıkarımı yeteneği, görüntü işleme, metin analizi ve zaman serisi veri analizinde kritik çözümler sunmaktadır. Ayrıca, farklı mimarilerin özel tasarımları, veri türüne özgü çözümler geliştirilmesini sağlar. Örneğin, Konvolüyonel Sinir Ağları (CNN), görüntü verilerini çok daha etkili bir şekilde analiz edebilir. Bu nedenle, derin öğrenme modelleri, görülmemiş verilerde bile görülmeyecek kadar üstün bir genelleştirme yeteneğine sahiptir.
Sonuç olarak, derin öğrenme modelleri, belirli veri türlerine göre özelleştirilebilir mimariler sunarak daha kapsamı ve verimli bir özellik çıkarımı sağlar. Bu özellik, derin öğrenmenin modern veri bilimi ve yapay zekâ uygulamalarındaki kritik rolünü ortaya koyar ve onu birçok karmaşık problemde vazgeçilmez bir araç haline getirir. Derin öğrenme, gelecekteki teknolojik gelişmelerde veri işleme kapasitesini daha da artırarak inovasyonu hızlandırmaya devam edecektir.



### References

[1] Fetzer, J. H., & Fetzer, J. H. (1990). What is artificial intelligence? (pp. 3-27). Springer Netherlands

[2] El Naqa, I., & Murphy, M. J. (2015). What is machine learning? (pp. 3-11). Springer International Publishing

[3] Hao, X., Zhang, G., & Ma, S. (2016). Deep learning. *International Journal of Semantic Computing, 10*(03), 417-439

[4] Montesinos López, O. A., Montesinos López, A., & Crossa, J. (2022). Fundamentals of artificial neural networks and deep learning. In *Multivariate statistical machine learning methods for genomic prediction* (pp. 379-425). Cham: Springer International Publishing

[5] Bishop, C. M., & Nasrabadi, N. M. (2006). *Pattern recognition and machine learning* (Vol. 4, No. 4, p. 738). New York: Springer

[6] Chollet, F. (2021). *Deep learning with Python*. Simon and Schuster

[7] Nair, V., & Hinton, G. E. (2010). Rectified linear units improve restricted boltzmann machines. In *Proceedings of the 27th international conference on machine learning (ICML-10)* (pp. 807-814)

[8] Kingma, D. P. (2014). Adam: A method for stochastic optimization. *arXiv preprint arXiv:1412.6980*
